"use strict";(globalThis.webpackChunkphysical_ai_curriculum_book=globalThis.webpackChunkphysical_ai_curriculum_book||[]).push([[396],{2068(n,e,i){i.r(e),i.d(e,{assets:()=>c,contentTitle:()=>s,default:()=>f,frontMatter:()=>o,metadata:()=>a,toc:()=>l});var t=i(4848),r=i(8453);const o={sidebar_position:3},s="Manipulation and Grasping",a={id:"module-3-ai-brain/week-11-12/manipulation-grasping",title:"Manipulation and Grasping",description:"Introduction to Manipulation in Humanoid Robots",source:"@site/docs/module-3-ai-brain/week-11-12/manipulation-grasping.md",sourceDirName:"module-3-ai-brain/week-11-12",slug:"/module-3-ai-brain/week-11-12/manipulation-grasping",permalink:"/physical-ai-curriculum-book/docs/module-3-ai-brain/week-11-12/manipulation-grasping",draft:!1,unlisted:!1,editUrl:"https://github.com/Anam-Noman/physical-ai-curriculum-book/edit/main/docs/module-3-ai-brain/week-11-12/manipulation-grasping.md",tags:[],version:"current",sidebarPosition:3,frontMatter:{sidebar_position:3},sidebar:"curriculumSidebar",previous:{title:"Bipedal Locomotion and Balance",permalink:"/physical-ai-curriculum-book/docs/module-3-ai-brain/week-11-12/locomotion-balance"},next:{title:"Human-Robot Interaction Design",permalink:"/physical-ai-curriculum-book/docs/module-3-ai-brain/week-11-12/hri-design"}},c={},l=[{value:"Introduction to Manipulation in Humanoid Robots",id:"introduction-to-manipulation-in-humanoid-robots",level:2},{value:"Grasp Planning and Analysis",id:"grasp-planning-and-analysis",level:2},{value:"Grasp Representation",id:"grasp-representation",level:3},{value:"Force Control and Impedance Control",id:"force-control-and-impedance-control",level:2},{value:"Force Control Implementation",id:"force-control-implementation",level:3},{value:"Dexterous Manipulation",id:"dexterous-manipulation",level:2},{value:"Multiple-Arm Coordination",id:"multiple-arm-coordination",level:3},{value:"Grasp Stability and Optimization",id:"grasp-stability-and-optimization",level:2},{value:"Robust Grasp Planning",id:"robust-grasp-planning",level:3},{value:"Practical Manipulation Examples",id:"practical-manipulation-examples",level:2},{value:"Picking and Placing",id:"picking-and-placing",level:3},{value:"Grasp Learning and Adaptation",id:"grasp-learning-and-adaptation",level:2},{value:"Adaptive Grasping Systems",id:"adaptive-grasping-systems",level:3},{value:"Troubleshooting Common Issues",id:"troubleshooting-common-issues",level:2},{value:"Issue 1: Grasp Failure",id:"issue-1-grasp-failure",level:3},{value:"Issue 2: Collision During Manipulation",id:"issue-2-collision-during-manipulation",level:3},{value:"Issue 3: Force Control Problems",id:"issue-3-force-control-problems",level:3},{value:"Issue 4: Grasp Planning Failure",id:"issue-4-grasp-planning-failure",level:3},{value:"Best Practices",id:"best-practices",level:2},{value:"Summary",id:"summary",level:2}];function p(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.h1,{id:"manipulation-and-grasping",children:"Manipulation and Grasping"}),"\n",(0,t.jsx)(e.h2,{id:"introduction-to-manipulation-in-humanoid-robots",children:"Introduction to Manipulation in Humanoid Robots"}),"\n",(0,t.jsx)(e.p,{children:"Humanoid manipulation involves the complex set of tasks performed by robot arms and hands to interact with objects in the environment. For humanoid robots, manipulation presents unique challenges due to the need to coordinate multiple degrees of freedom while maintaining balance and considering the robot's whole-body dynamics. This capability is essential for humanoid robots to perform meaningful tasks in human environments, from picking up objects to complex interactions with tools."}),"\n",(0,t.jsx)(e.p,{children:"Manipulation in humanoid robots encompasses:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Grasping"}),": Establishing firm contact with objects"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Transport"}),": Moving objects from one location to another"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Articulation"}),": Manipulating objects with joints or movable parts"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Assembly"}),": Combining objects to create new structures"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Delicate Handling"}),": Managing fragile or soft objects"]}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"grasp-planning-and-analysis",children:"Grasp Planning and Analysis"}),"\n",(0,t.jsx)(e.h3,{id:"grasp-representation",children:"Grasp Representation"}),"\n",(0,t.jsx)(e.p,{children:"A grasp is typically represented by:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Grasp pose"}),": Position and orientation of the hand relative to the object"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Contact points"}),": Locations where fingers make contact with the object"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Grasp type"}),": Classification of the grasp (power, precision, etc.)"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Force distribution"}),": How forces are applied at contact points"]}),"\n"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"import numpy as np\nfrom geometry_msgs.msg import Pose, Point\nfrom scipy.spatial.transform import Rotation as R\n\nclass Grasp:\n    def __init__(self, pose, grasp_type, finger_positions, contact_forces):\n        \"\"\"\n        Represents a robotic grasp\n        \n        Args:\n            pose: Pose of the hand (position and orientation)\n            grasp_type: Type of grasp (e.g., 'power', 'precision')\n            finger_positions: Positions of fingertips in hand frame\n            contact_forces: Forces applied at contact points\n        \"\"\"\n        self.pose = pose\n        self.grasp_type = grasp_type\n        self.finger_positions = finger_positions\n        self.contact_forces = contact_forces\n        self.quality = None  # Will be computed later\n\nclass GraspPlanner:\n    def __init__(self, robot_params):\n        self.robot_params = robot_params\n        self.hand_model = self.initialize_hand_model()\n        self.object_database = self.load_object_database()\n    \n    def initialize_hand_model(self):\n        \"\"\"\n        Initialize model of the robotic hand\n        \"\"\"\n        hand_model = {\n            'num_fingers': 5,\n            'finger_lengths': [0.05, 0.055, 0.05, 0.045, 0.04],  # Thumb, index, etc.\n            'joint_limits': {\n                'thumb': [0, 90],  # Limits for abduction and flexion\n                'fingers': [0, 120]  # Joint limits for other fingers\n            },\n            'friction_coeff': 0.8,\n            'max_force': 20.0  # Max force per finger in Newtons\n        }\n        return hand_model\n    \n    def load_object_database(self):\n        \"\"\"\n        Load information about known objects in the environment\n        \"\"\"\n        # In practice, this would load from a real database with object properties\n        return {\n            'cup': {\n                'shape': 'cylinder',\n                'dims': [0.08, 0.1],  # diameter, height\n                'mass': 0.2,\n                'com_offset': [0, 0, 0.05],\n                'friction': 0.6,\n                'stability_points': ['handle']  # Where the object is easiest to grasp\n            },\n            'book': {\n                'shape': 'box',\n                'dims': [0.2, 0.15, 0.03],  # width, height, depth\n                'mass': 0.5,\n                'com_offset': [0, 0, 0],\n                'friction': 0.7\n            }\n        }\n\n    def generate_grasp_candidates(self, target_object):\n        \"\"\"\n        Generate potential grasp candidates for the target object\n        \"\"\"\n        candidates = []\n        \n        obj_shape = target_object['shape']\n        obj_dims = target_object['dims']\n        \n        if obj_shape == 'cylinder':\n            # Generate cylindrical grasp candidates\n            candidates.extend(self._cylindrical_grasps(target_object))\n        elif obj_shape == 'box':\n            # Generate box grasp candidates\n            candidates.extend(self._box_grasps(target_object))\n        else:\n            # For unknown shapes, generate general grasp points\n            candidates.extend(self._general_grasps(target_object))\n        \n        return candidates\n\n    def _cylindrical_grasps(self, obj):\n        \"\"\"\n        Generate grasp candidates for cylindrical objects\n        \"\"\"\n        candidates = []\n        dims = obj['dims']  # [diameter, height]\n        \n        # Power grasp for lifting cylinder\n        for angle in np.linspace(0, 2*np.pi, 8):  # 8 orientations around the cylinder\n            pose = Pose()\n            # Position the hand at the center of the cylinder, oriented to wrap around it\n            pose.position.x = 0.0\n            pose.position.y = 0.0\n            pose.position.z = dims[1] / 2.0  # At the halfway point\n            \n            # Orient the hand to wrap around the cylinder\n            rot = R.from_euler('xyz', [0, 0, angle]).as_quat()\n            pose.orientation.x = rot[0]\n            pose.orientation.y = rot[1]\n            pose.orientation.z = rot[2]\n            pose.orientation.w = rot[3]\n            \n            # Define finger positions for cylindrical grasp\n            finger_positions = self._cylindrical_finger_positions(dims, angle)\n            \n            grasp = Grasp(\n                pose=pose,\n                grasp_type='cylindrical_power',\n                finger_positions=finger_positions,\n                contact_forces=self._calculate_initial_forces(obj)\n            )\n            \n            candidates.append(grasp)\n        \n        # Precision grasp for handling cup by handle\n        if obj.get('has_handle', False):\n            handle_pose = self._calculate_handle_pose(obj)\n            if handle_pose:\n                precision_grasp = Grasp(\n                    pose=handle_pose,\n                    grasp_type='precision_pinch',\n                    finger_positions=self._precision_finger_positions(),\n                    contact_forces=self._calculate_precision_forces(obj)\n                )\n                candidates.append(precision_grasp)\n        \n        return candidates\n\n    def _box_grasps(self, obj):\n        \"\"\"\n        Generate grasp candidates for box-shaped objects\n        \"\"\"\n        candidates = []\n        dims = obj['dims']  # [width, height, depth]\n        \n        # Generate corner grasps\n        corner_offsets = [\n            [dims[0]/2, dims[1]/2, dims[2]/2],   # Top right corner\n            [dims[0]/2, -dims[1]/2, dims[2]/2],  # Top left corner\n            [-dims[0]/2, dims[1]/2, dims[2]/2],  # Bottom right corner\n            [-dims[0]/2, -dims[1]/2, dims[2]/2], # Bottom left corner\n        ]\n        \n        for offset in corner_offsets:\n            for orient_idx in range(4):  # 4 different orientations\n                pose = Pose()\n                pose.position.x = offset[0]\n                pose.position.y = offset[1]\n                pose.position.z = offset[2]\n                \n                # Rotate the hand for different orientations\n                angle = orient_idx * np.pi / 2\n                rot = R.from_euler('z', angle).as_quat()\n                pose.orientation.x = rot[0]\n                pose.orientation.y = rot[1]\n                pose.orientation.z = rot[2]\n                pose.orientation.w = rot[3]\n                \n                grasp = Grasp(\n                    pose=pose,\n                    grasp_type='corner_grasp',\n                    finger_positions=self._box_corner_finger_positions(offset),\n                    contact_forces=self._calculate_box_forces(obj)\n                )\n                \n                candidates.append(grasp)\n        \n        return candidates\n\n    def _calculate_grasp_quality(self, grasp, target_object):\n        \"\"\"\n        Calculate quality metrics for a given grasp\n        \"\"\"\n        # Quality metrics:\n        # 1. Force closure: Can resist arbitrary wrenches?\n        # 2. Torque efficiency: Minimal force to resist load?\n        # 3. Stability: Robust to small perturbations?\n        \n        quality_metrics = {\n            'force_closure': self._check_force_closure(grasp),\n            'wrench_resistance': self._calculate_wrench_resistance(grasp, target_object),\n            'stability': self._calculate_stability(grasp, target_object),\n            'accessibility': self._check_accessibility(grasp),\n            'comfort': self._calculate_comfort(grasp)\n        }\n        \n        # Combine metrics into single quality score\n        weights = {\n            'force_closure': 0.35,\n            'wrench_resistance': 0.25,\n            'stability': 0.20,\n            'accessibility': 0.15,\n            'comfort': 0.05\n        }\n        \n        quality = sum(weights[k] * v for k, v in quality_metrics.items()) if all(isinstance(v, (int, float)) for v in quality_metrics.values()) else 0.0\n        \n        return quality, quality_metrics\n\n    def _check_force_closure(self, grasp):\n        \"\"\"\n        Check if the grasp provides force closure\n        \"\"\"\n        # Simplified: check if contact points provide sufficient constraint\n        # A proper implementation would use the grasp matrix and check if it can resist arbitrary wrenches\n        contact_points = grasp.finger_positions\n        if len(contact_points) < 3:\n            return 0.0  # Need at least 3 contacts for planar objects\n        \n        # In 3D space, we typically need more contacts for full force closure\n        # For a 3D object, we need at least 7 contact points for force closure\n        # But for practical purposes in robotics, 4-5 contacts is often sufficient\n        if len(contact_points) >= 4:\n            return 1.0\n        else:\n            return 0.5  # Partial score if between 3 and 4 contacts\n\n    def _calculate_wrench_resistance(self, grasp, obj):\n        \"\"\"\n        Calculate how well the grasp can resist external wrenches\n        \"\"\"\n        # This would involve computing the grasp wrench space\n        # For simplicity, we'll estimate based on friction cones and force distribution\n        \n        # Calculate total force that can be applied before slipping\n        max_total_force = sum(min(finger_force, self.hand_model['max_force']) \n                             for finger_force in grasp.contact_forces)\n        \n        # Account for friction coefficient\n        resistance = max_total_force * obj.get('friction', 0.5)\n        \n        # Normalize against object weight\n        obj_weight = obj['mass'] * 9.81\n        normalized_resistance = min(1.0, resistance / obj_weight)\n        \n        return normalized_resistance\n\n    def _calculate_stability(self, grasp, obj):\n        \"\"\"\n        Calculate grasp stability to small perturbations\n        \"\"\"\n        # Stability depends on contact geometry and object COG\n        cog = obj.get('com_offset', [0, 0, 0])\n        \n        # Calculate distance from grasp center to COG\n        grasp_center = self._compute_grasp_center(grasp)\n        cog_distance = np.linalg.norm(np.array(grasp_center) - np.array(cog))\n        \n        # Stability decreases with distance from COG\n        # Max stability when grasp is near COG\n        max_stable_distance = max(obj['dims']) * 0.5  # Half the largest dimension\n        stability = max(0.0, 1.0 - (cog_distance / max_stable_distance))\n        \n        return stability\n\n    def _check_accessibility(self, grasp):\n        \"\"\"\n        Check if the grasp is physically accessible by the robot\n        \"\"\"\n        # This would involve inverse kinematics to check if the robot can reach the grasp pose\n        # For now, return a simplified estimate\n        # In reality, we'd check if IK solution exists\n        return 0.8  # Assume 80% of random poses are accessible\n\n    def _calculate_comfort(self, grasp):\n        \"\"\"\n        Calculate how comfortable the grasp is for the hand configuration\n        \"\"\"\n        # Comfort is related to how close joint angles are to neutral position\n        # For this simplified model, assume neutral configuration has high comfort\n        return 0.9  # High comfort for now\n\n    def _compute_grasp_center(self, grasp):\n        \"\"\"\n        Compute the effective center of the grasp based on contact points\n        \"\"\"\n        if not grasp.finger_positions:\n            return [0, 0, 0]\n        \n        center = np.mean(grasp.finger_positions, axis=0)\n        return center\n\n    def rank_grasps(self, grasp_candidates, target_object):\n        \"\"\"\n        Rank grasp candidates by quality and other criteria\n        \"\"\"\n        ranked_grasps = []\n        \n        for grasp in grasp_candidates:\n            quality, metrics = self._calculate_grasp_quality(grasp, target_object)\n            grasp.quality = quality\n            \n            ranked_grasps.append({\n                'grasp': grasp,\n                'quality': quality,\n                'metrics': metrics\n            })\n        \n        # Sort by quality score\n        ranked_grasps.sort(key=lambda x: x['quality'], reverse=True)\n        \n        return ranked_grasps\n"})}),"\n",(0,t.jsx)(e.h2,{id:"force-control-and-impedance-control",children:"Force Control and Impedance Control"}),"\n",(0,t.jsx)(e.p,{children:"Effective manipulation requires precise control of forces applied to objects, especially when dealing with varying surface geometries and material properties."}),"\n",(0,t.jsx)(e.h3,{id:"force-control-implementation",children:"Force Control Implementation"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'class ForceController:\n    def __init__(self, robot_params):\n        self.params = robot_params\n        self.kp_force = 50.0  # Proportional gain for force control\n        self.ki_force = 10.0  # Integral gain for force control\n        self.kd_force = 5.0   # Derivative gain for force control\n        self.force_integral = 0.0\n        self.previous_force_error = 0.0\n        \n    def force_control_step(self, current_force, desired_force, dt):\n        """\n        Calculate control output for force control\n        """\n        # Calculate force error\n        force_error = desired_force - current_force\n        \n        # Update integral term\n        self.force_integral += force_error * dt\n        \n        # Calculate derivative term\n        force_derivative = (force_error - self.previous_force_error) / dt if dt > 0 else 0\n        \n        # Apply PID control\n        control_output = (self.kp_force * force_error + \n                         self.ki_force * self.force_integral + \n                         self.kd_force * force_derivative)\n        \n        self.previous_force_error = force_error\n        \n        return control_output\n\nclass ImpedanceController:\n    def __init__(self, robot_params):\n        self.params = robot_params\n        # Impedance parameters (mass, damping, stiffness)\n        self.mass_impedance = np.diag([10.0, 10.0, 10.0])  # kg\n        self.damping_impedance = np.diag([200.0, 200.0, 200.0])  # Ns/m\n        self.stiffness_impedance = np.diag([1000.0, 1000.0, 1000.0])  # N/m\n        \n    def calculate_impedance_force(self, position_error, velocity_error):\n        """\n        Calculate impedance control force\n        F = M*d2x_desired + B*dx_error + K*x_error\n        """\n        # For impedance control: F = M(ddx_cmd) + B(dx_error) + K(x_error)\n        # Where ddx_cmd is the desired acceleration\n        impedance_force = (np.dot(self.mass_impedance, np.zeros(3)) +  # No desired acc\n                          np.dot(self.damping_impedance, velocity_error) + \n                          np.dot(self.stiffness_impedance, position_error))\n        \n        return impedance_force\n    \n    def adaptive_impedance(self, task_phase, environment_stiffness):\n        """\n        Adjust impedance parameters based on task requirements\n        """\n        if task_phase == \'approach\':\n            # Low stiffness for safe approach\n            self.stiffness_impedance = np.diag([100.0, 100.0, 100.0])\n        elif task_phase == \'contact\':\n            # Moderate stiffness for contact establishment\n            self.stiffness_impedance = np.diag([500.0, 500.0, 500.0])\n        elif task_phase == \'manipulation\':\n            # High stiffness for precise manipulation\n            self.stiffness_impedance = np.diag([2000.0, 2000.0, 2000.0])\n        elif task_phase == \'release\':\n            # Low stiffness for safe release\n            self.stiffness_impedance = np.diag([100.0, 100.0, 100.0])\n        \n        # Adjust damping based on environment stiffness\n        self.damping_impedance = self.damping_impedance * (1.0 + environment_stiffness / 1000.0)\n\nclass HybridForcePositionController:\n    def __init__(self, robot_params):\n        self.params = robot_params\n        self.position_controller = self._init_position_controller()\n        self.force_controller = ForceController(robot_params)\n        self.impedance_controller = ImpedanceController(robot_params)\n        \n    def _init_position_controller(self):\n        """Initialize position controller with PD control"""\n        return {\n            \'kp\': 1000.0,  # Position proportional gain\n            \'kv\': 50.0     # Velocity (damping) gain\n        }\n    \n    def hybrid_control(self, pose_desired, pose_actual, \n                      force_desired, force_actual, dt):\n        """\n        Implement hybrid force/position control\n        Control in position directions, force in constrained directions\n        """\n        # Calculate pose errors\n        pos_error = pose_desired.position - pose_actual.position\n        vel_error = pose_desired.velocity - pose_actual.velocity\n        \n        # Calculate force errors\n        force_error = force_desired - force_actual\n        \n        # For hybrid control, determine which directions need position control\n        # and which need force control\n        # This depends on the task and constraints\n        \n        # Example: Position control in X,Y; Force control in Z\n        control_output = np.zeros(6)  # 3 position + 3 orientation\n        \n        # Position control for X, Y, and orientation\n        control_output[0:2] = (self.position_controller[\'kp\'] * pos_error[0:2] + \n                              self.position_controller[\'kv\'] * vel_error[0:2])  # X, Y\n        control_output[3:6] = (self.position_controller[\'kp\'] * pos_error[3:6] + \n                              self.position_controller[\'kv\'] * vel_error[3:6])  # Orientation\n        \n        # Force control for Z (normal to surface)\n        z_force_control = self.force_controller.force_control_step(\n            force_actual[2], force_desired[2], dt\n        )\n        control_output[2] = z_force_control  # Z force\n        \n        return control_output\n'})}),"\n",(0,t.jsx)(e.h2,{id:"dexterous-manipulation",children:"Dexterous Manipulation"}),"\n",(0,t.jsx)(e.h3,{id:"multiple-arm-coordination",children:"Multiple-Arm Coordination"}),"\n",(0,t.jsx)(e.p,{children:"Humanoid robots often have two arms that can work together for complex manipulation tasks:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"class BimanualCoordination:\n    def __init__(self, robot_params):\n        self.params = robot_params\n        self.left_arm_controller = ArmController('left', robot_params)\n        self.right_arm_controller = ArmController('right', robot_params)\n        self.coordination_manager = CoordinationManager(robot_params)\n        \n    def coordinated_grasp(self, object_info, grasp_type='passive_holder'):\n        \"\"\"\n        Coordinate both arms for a cooperative grasp\n        grasp_type: 'passive_holder' (one holds, other manipulates)\n                   'active_cooperation' (both actively participate)\n                   'symmetric' (both apply same motion)\n        \"\"\"\n        if grasp_type == 'passive_holder':\n            # Right hand holds object firmly\n            right_grasp = self.right_arm_controller.plan_grasp(object_info, 'firm_hold')\n            \n            # Left hand manipulates or applies force\n            left_manipulation = self.left_arm_controller.plan_manipulation(\n                object_info, \n                'apply_torque'\n            )\n            \n            # Ensure right hand maintains grasp while left manipulates\n            self.enforce_constraint(right_grasp, left_manipulation, 'no_slip')\n            \n        elif grasp_type == 'active_cooperation':\n            # Both hands actively participate in manipulation\n            left_grasp, right_grasp = self.plan_bilateral_grasp(object_info)\n            \n            # Calculate coordinated motion\n            bilateral_motion = self.plan_bilateral_motion(\n                left_grasp, right_grasp, object_info\n            )\n            \n        elif grasp_type == 'symmetric':\n            # Both hands apply symmetric motion\n            symmetric_grasp = self.plan_symmetric_grasp(object_info)\n            bilateral_motion = self.plan_symmetric_motion(symmetric_grasp)\n        \n        return bilateral_motion\n    \n    def plan_bilateral_grasp(self, object_info):\n        \"\"\"\n        Plan coordinated grasp with both arms\n        \"\"\"\n        # Determine optimal grasp points for each hand\n        # This involves solving for stable grasp configuration considering both hands\n        object_dims = object_info['dimensions']\n        \n        # For a simple object like a box, determine grasp points\n        if object_info['shape'] == 'box':\n            # Left hand grasps one side, right hand grasps opposite side\n            left_grasp_pos = np.array([-object_dims[0]/2, 0, 0])\n            right_grasp_pos = np.array([object_dims[0]/2, 0, 0])\n        else:\n            # For other shapes, calculate appropriate grasp points\n            left_grasp_pos, right_grasp_pos = self.calculate_opposing_grasps(object_info)\n        \n        # Plan grasp orientation for each hand\n        left_grasp_orient = self.calculate_grasp_orientation(left_grasp_pos, object_info)\n        right_grasp_orient = self.calculate_grasp_orientation(right_grasp_pos, object_info)\n        \n        return (left_grasp_orient, right_grasp_orient)\n    \n    def enforce_constraint(self, grasp1, grasp2, constraint_type):\n        \"\"\"\n        Enforce constraint between two grasps\n        \"\"\"\n        if constraint_type == 'no_slip':\n            # Ensure both grasps maintain sufficient friction to prevent object slip\n            self.verify_friction_constraints(grasp1, grasp2)\n        \n        elif constraint_type == 'rigid_coupling':\n            # Maintain rigid connection between hands through object\n            self.update_kinematic_chain(grasp1, grasp2)\n    \n    def calculate_opposing_grasps(self, object_info):\n        \"\"\"\n        Calculate opposing grasp points for an arbitrary object\n        \"\"\"\n        # This would typically involve finding antipodal grasp points\n        # For now, use simplified approach based on bounding box\n        bounding_box = self.approximate_bounding_box(object_info)\n        \n        # Find longest dimension and grasp on opposite sides\n        dimensions = [abs(bounding_box[1][i] - bounding_box[0][i]) for i in range(3)]\n        max_dim_idx = np.argmax(dimensions)\n        \n        grasp1 = np.zeros(3)\n        grasp2 = np.zeros(3)\n        \n        # Place grasps on opposite sides of the longest dimension\n        grasp1[max_dim_idx] = bounding_box[0][max_dim_idx]\n        grasp2[max_dim_idx] = bounding_box[1][max_dim_idx]\n        \n        # Center in other dimensions\n        for i in range(3):\n            if i != max_dim_idx:\n                center = (bounding_box[0][i] + bounding_box[1][i]) / 2\n                grasp1[i] = center\n                grasp2[i] = center\n        \n        return grasp1, grasp2\n    \n    def approximate_bounding_box(self, object_info):\n        \"\"\"\n        Approximate bounding box for the object\n        \"\"\"\n        # This would come from perception system in practice\n        # For example, if we know object is centered at origin with dimensions\n        dimensions = object_info.get('dimensions', [0.1, 0.1, 0.1])\n        center = object_info.get('center', [0, 0, 0])\n        \n        min_point = [center[i] - dimensions[i]/2 for i in range(3)]\n        max_point = [center[i] + dimensions[i]/2 for i in range(3)]\n        \n        return [min_point, max_point]\n    \n    def calculate_grasp_orientation(self, grasp_position, object_info):\n        \"\"\"\n        Calculate proper grasp orientation at given position\n        \"\"\"\n        # This depends on the object and task\n        # For a simple approach, orient perpendicular to the surface normal at grasp point\n        surface_normal = self.estimate_surface_normal(grasp_position, object_info)\n        \n        # Calculate a suitable approach direction (often perpendicular to normal)\n        approach_dir = self.calculate_approach_direction(surface_normal)\n        \n        # Create grasp orientation\n        grasp_quaternion = self.align_with_surface(approach_dir, surface_normal)\n        \n        return {\n            'position': grasp_position,\n            'orientation': grasp_quaternion,\n            'approach_direction': approach_dir\n        }\n    \n    def estimate_surface_normal(self, point, object_info):\n        \"\"\"\n        Estimate surface normal at a given point on the object\n        \"\"\"\n        # Simplified approach: for common shapes, use analytical formulas\n        shape = object_info.get('shape', 'box')\n        \n        if shape == 'box':\n            # For box, determine which face the point is closest to\n            dims = object_info['dimensions']\n            center = np.array(object_info.get('center', [0, 0, 0]))\n            \n            # Calculate relative position\n            rel_pos = np.array(point) - center\n            \n            # Determine closest face (largest absolute coordinate)\n            face_idx = np.argmax(np.abs(rel_pos))\n            \n            normal = np.zeros(3)\n            sign = 1 if rel_pos[face_idx] >= 0 else -1\n            normal[face_idx] = sign\n            \n            return normal\n        \n        else:\n            # For other shapes, would need more sophisticated calculation\n            return np.array([0, 0, 1])  # Default: up direction\n\nclass CoordinationManager:\n    def __init__(self, robot_params):\n        self.params = robot_params\n        self.workspace_overlap = self.calculate_workspace_overlap()\n    \n    def calculate_workspace_overlap(self):\n        \"\"\"\n        Calculate overlapping workspace between two arms\n        \"\"\"\n        # This would involve calculating reachability for each arm\n        # and finding the intersection of their workspaces\n        return {\n            'volume': 0.5,  # m^3\n            'optimal_region': np.array([0, 0, 0.8])  # Center of overlapping region\n        }\n    \n    def coordinate_movement(self, left_target, right_target):\n        \"\"\"\n        Coordinate movement of both arms to avoid collisions and optimize performance\n        \"\"\"\n        # Check workspace feasibility\n        if not self.is_reachable(left_target, 'left') or not self.is_reachable(right_target, 'right'):\n            raise ValueError(\"Targets not reachable by respective arms\")\n        \n        # Check for potential collisions\n        if self.would_collide(left_target, right_target):\n            # Plan collision-free trajectory\n            coordinated_traj = self.plan_collision_free_trajectory(left_target, right_target)\n        else:\n            # Plan independent trajectories\n            coordinated_traj = {\n                'left_arm': self.plan_trajectory_to_target(left_target, 'left'),\n                'right_arm': self.plan_trajectory_to_target(right_target, 'right')\n            }\n        \n        return coordinated_traj\n    \n    def would_collide(self, left_pose, right_pose):\n        \"\"\"\n        Check if arm poses would result in collision\n        \"\"\"\n        # Simplified collision check - in reality would use full collision detection\n        left_pos = np.array(left_pose[:3]) if len(left_pose) >= 3 else np.array(left_pose)\n        right_pos = np.array(right_pose[:3]) if len(right_pose) >= 3 else np.array(right_pose)\n        \n        # Check if arms are too close together\n        distance = np.linalg.norm(left_pos - right_pos)\n        \n        # Conservative collision threshold based on arm length\n        min_safe_distance = 0.2  # 20 cm minimum separation\n        \n        return distance < min_safe_distance\n    \n    def plan_collision_free_trajectory(self, left_target, right_target):\n        \"\"\"\n        Plan trajectories that avoid collisions between arms\n        \"\"\"\n        # This would implement more sophisticated coordination\n        # For now, just return a placeholder\n        return {\n            'left_arm': [left_target],  # Direct path\n            'right_arm': [right_target],  # Direct path\n            'coordination_required': True\n        }\n"})}),"\n",(0,t.jsx)(e.h2,{id:"grasp-stability-and-optimization",children:"Grasp Stability and Optimization"}),"\n",(0,t.jsx)(e.h3,{id:"robust-grasp-planning",children:"Robust Grasp Planning"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'class RobustGraspPlanner:\n    def __init__(self, robot_params):\n        self.params = robot_params\n        self.uncertainty_model = self.build_uncertainty_model()\n        self.stability_evaluator = StabilityEvaluator()\n        \n    def build_uncertainty_model(self):\n        """\n        Build model of uncertainties in grasp planning\n        """\n        return {\n            \'object_pose_uncertainty\': 0.01,  # 1cm in position\n            \'object_dim_uncertainty\': 0.005,  # 5mm in dimensions\n            \'friction_coeff_uncertainty\': 0.1,  # 10% in friction\n            \'sensor_noise_level\': 0.002,  # 2mm sensor noise\n            \'actuation_precision\': 0.003  # 3mm actuator precision\n        }\n    \n    def plan_robust_grasp(self, object_info, success_probability=0.95):\n        """\n        Plan grasp that is robust to uncertainties\n        """\n        # Generate many grasp candidates with perturbations\n        robust_candidates = []\n        \n        # Try multiple perturbation levels\n        for perturbation_level in [0.001, 0.002, 0.005, 0.01]:\n            # Generate base grasp candidates\n            base_candidates = self.generate_grasp_candidates_with_uncertainty(\n                object_info, perturbation_level\n            )\n            \n            # Evaluate robustness of each candidate\n            for candidate in base_candidates:\n                robustness_score = self.evaluate_robustness(\n                    candidate, object_info, perturbation_level\n                )\n                \n                if robustness_score >= success_probability:\n                    robust_candidates.append({\n                        \'grasp\': candidate,\n                        \'robustness_score\': robustness_score,\n                        \'perturbation_level\': perturbation_level\n                    })\n        \n        # Sort by robustness score\n        robust_candidates.sort(key=lambda x: x[\'robustness_score\'], reverse=True)\n        \n        return robust_candidates\n    \n    def generate_grasp_candidates_with_uncertainty(self, object_info, perturbation_level):\n        """\n        Generate grasp candidates considering uncertainty in object properties\n        """\n        base_candidates = self.generate_grasp_candidates(object_info)\n        perturbed_candidates = []\n        \n        num_perturbations = 20  # Number of perturbations to try\n        \n        for base_grasp in base_candidates:\n            for _ in range(num_perturbations):\n                # Perturb object properties\n                perturbed_object = self.perturb_object_properties(\n                    object_info, perturbation_level\n                )\n                \n                # Adjust grasp based on perturbed object\n                adjusted_grasp = self.adjust_grasp_for_perturbed_object(\n                    base_grasp, perturbed_object\n                )\n                \n                perturbed_candidates.append(adjusted_grasp)\n        \n        return perturbed_candidates\n    \n    def perturb_object_properties(self, object_info, perturbation_level):\n        """\n        Apply random perturbations to object properties based on uncertainty model\n        """\n        perturbed = object_info.copy()\n        \n        # Perturb position\n        pos_perturbation = np.random.normal(0, self.uncertainty_model[\'object_pose_uncertainty\'], 3)\n        if \'center\' in perturbed:\n            perturbed[\'center\'] = np.array(perturbed[\'center\']) + pos_perturbation\n        \n        # Perturb dimensions\n        dim_perturbation = np.random.normal(0, self.uncertainty_model[\'object_dim_uncertainty\'], len(perturbed[\'dimensions\']))\n        perturbed[\'dimensions\'] = np.array(perturbed[\'dimensions\']) + dim_perturbation\n        \n        # Ensure positive dimensions\n        perturbed[\'dimensions\'] = np.maximum(perturbed[\'dimensions\'], 0.001)\n        \n        # Perturb friction coefficient\n        friction_perturbation = np.random.normal(0, self.uncertainty_model[\'friction_coeff_uncertainty\'])\n        if \'friction\' in perturbed:\n            perturbed[\'friction\'] = max(0.1, perturbed[\'friction\'] + friction_perturbation)\n        \n        return perturbed\n    \n    def adjust_grasp_for_perturbed_object(self, base_grasp, perturbed_object):\n        """\n        Adjust grasp based on perturbed object properties\n        """\n        # Copy base grasp\n        adjusted_grasp = Grasp(\n            pose=base_grasp.pose,\n            grasp_type=base_grasp.grasp_type,\n            finger_positions=base_grasp.finger_positions.copy(),\n            contact_forces=base_grasp.contact_forces.copy()\n        )\n        \n        # Adjust finger positions based on new object dimensions\n        # This is a simplified adjustment - in reality would need more sophisticated planning\n        \n        return adjusted_grasp\n    \n    def evaluate_robustness(self, grasp, object_info, perturbation_level):\n        """\n        Evaluate how robust the grasp is to perturbations\n        """\n        num_evaluations = 50\n        successful_grasps = 0\n        \n        for _ in range(num_evaluations):\n            # Apply random perturbation\n            perturbed_object = self.perturb_object_properties(object_info, perturbation_level)\n            \n            # Evaluate grasp on perturbed object\n            if self.evaluate_grasp_stability(grasp, perturbed_object):\n                successful_grasps += 1\n        \n        robustness_score = successful_grasps / num_evaluations\n        return robustness_score\n    \n    def evaluate_grasp_stability(self, grasp, object_info):\n        """\n        Evaluate if a grasp is stable on the given object\n        """\n        # Implement stability evaluation using mechanics\n        try:\n            # Check force closure\n            if not self.check_force_closure(grasp, object_info):\n                return False\n            \n            # Check that grasp can resist gravity\n            if not self.can_resist_gravity(grasp, object_info):\n                return False\n            \n            # Check that grasp is not slippable\n            if self.is_slippable(grasp, object_info):\n                return False\n            \n            # All checks passed\n            return True\n            \n        except Exception:\n            return False\n    \n    def check_force_closure(self, grasp, object_info):\n        """\n        Check if the grasp provides force closure\n        """\n        # Simplified force closure check\n        # In reality would use grasp matrix and check if it spans the wrench space\n        contact_points = grasp.finger_positions\n        if len(contact_points) < 2:\n            return False\n        \n        # For a 3D object, we need at least 7 contacts for full force closure\n        # But for practical purposes, 4-5 contacts with good friction is usually sufficient\n        num_contacts = len(contact_points)\n        friction_coef = object_info.get(\'friction\', 0.6)\n        \n        # Minimum requirement: at least 2 contacts with sufficient friction\n        if num_contacts >= 2 and friction_coef > 0.3:\n            return True\n        else:\n            return False\n    \n    def can_resist_gravity(self, grasp, object_info):\n        """\n        Check if grasp can resist the object\'s weight\n        """\n        object_weight = object_info[\'mass\'] * 9.81\n        max_grasp_force = self.get_maximum_grasp_force(grasp)\n        \n        return max_grasp_force > object_weight\n    \n    def is_slippable(self, grasp, object_info):\n        """\n        Check if the grasp is prone to slippage\n        """\n        # Calculate if the applied forces exceed friction limits\n        contact_forces = grasp.contact_forces\n        friction_coef = object_info.get(\'friction\', 0.6)\n        \n        # Check each contact against friction cone constraint\n        for i, force in enumerate(contact_forces):\n            if isinstance(force, (list, tuple, np.ndarray)):\n                force_norm = np.linalg.norm(force)\n            else:\n                force_norm = abs(force)\n                \n            # Simplified: if normal force component is not sufficient to resist tangential forces\n            # This is a very simplified check\n            max_friction_force = force_norm * friction_coef\n            \n            # For this simplified example, assume tangential force is half the normal force\n            tangential_force = force_norm * 0.5\n            \n            if tangential_force > max_friction_force:\n                return True  # Would slip\n        \n        return False\n\nclass StabilityEvaluator:\n    def __init__(self):\n        self.evaluation_methods = [\n            self._evaluate_form_closure,\n            self._evaluate_force_closure,\n            self._evaluate_friction_constraints,\n            self._evaluate_dynamic_stability\n        ]\n    \n    def evaluate_grasp_stability(self, grasp, object_info):\n        """\n        Comprehensive stability evaluation\n        """\n        scores = {}\n        \n        for method in self.evaluation_methods:\n            score = method(grasp, object_info)\n            method_name = method.__name__\n            scores[method_name] = score\n        \n        # Calculate composite stability score\n        weights = {\n            \'_evaluate_form_closure\': 0.2,\n            \'_evaluate_force_closure\': 0.3,\n            \'_evaluate_friction_constraints\': 0.3,\n            \'_evaluate_dynamic_stability\': 0.2\n        }\n        \n        composite_score = sum(weights[method] * scores[method] for method in scores)\n        \n        return composite_score, scores\n    \n    def _evaluate_form_closure(self, grasp, object_info):\n        """\n        Evaluate form closure (geometric constraints)\n        """\n        # Form closure exists when object is geometrically constrained\n        # This is a simplified check - real evaluation would be more complex\n        contact_points = grasp.finger_positions\n        \n        if len(contact_points) < 4:\n            return 0.0  # No form closure possible with < 4 points\n        \n        # Check if contact points can constrain all DOFs\n        # For a sphere, 7 points are needed for form closure\n        # For general objects, minimum is 7 points\n        if len(contact_points) >= 7:\n            return 1.0\n        elif len(contact_points) >= 4:\n            return 0.7  # Good for many practical objects\n        else:\n            return 0.0\n    \n    def _evaluate_force_closure(self, grasp, object_info):\n        """\n        Evaluate force closure (ability to resist arbitrary wrenches)\n        """\n        # Check if the grasp can theoretically resist any external wrench\n        # This would normally involve computing the grasp matrix\n        contact_points = grasp.finger_positions\n        \n        if len(contact_points) < 2:\n            return 0.0\n        \n        # For 3D objects, minimum contacts for force closure\n        friction_coef = object_info.get(\'friction\', 0.6)\n        \n        if len(contact_points) >= 4 and friction_coef > 0.4:\n            return 1.0\n        elif len(contact_points) >= 3 and friction_coef > 0.6:\n            return 0.8\n        elif len(contact_points) >= 2 and friction_coef > 0.8:\n            return 0.5\n        else:\n            return 0.0\n    \n    def _evaluate_friction_constraints(self, grasp, object_info):\n        """\n        Evaluate friction-based constraints\n        """\n        # Check if applied forces respect friction limits\n        contact_points = grasp.finger_positions\n        contact_forces = grasp.contact_forces\n        friction_coef = object_info.get(\'friction\', 0.6)\n        \n        if len(contact_points) == 0 or len(contact_forces) == 0:\n            return 0.0\n        \n        # Calculate friction constraints satisfaction\n        satisfied_constraints = 0\n        total_constraints = len(contact_forces)\n        \n        for force in contact_forces:\n            force_mag = abs(force) if isinstance(force, (int, float)) else np.linalg.norm(force)\n            friction_limit = friction_coef * force_mag  # Simplified\n            \n            # Assume force is within friction limit for this evaluation\n            satisfied_constraints += 1\n        \n        return satisfied_constraints / total_constraints if total_constraints > 0 else 0.0\n    \n    def _evaluate_dynamic_stability(self, grasp, object_info):\n        """\n        Evaluate stability under dynamic conditions\n        """\n        # Consider dynamic effects like acceleration, jerks, etc.\n        mass = object_info[\'mass\']\n        gravity = 9.81\n        \n        # Stability under acceleration\n        acceleration_threshold = 5.0  # m/s^2 maximum acceleration before concern\n        max_acceptable_inertia_force = mass * acceleration_threshold\n        \n        # Simplified check: if object weight is much less than acceptable force, it\'s stable\n        weight = mass * gravity\n        \n        if max_acceptable_inertia_force > weight * 3:  # 3x safety factor\n            return 1.0\n        elif max_acceptable_inertia_force > weight:\n            return 0.7\n        else:\n            return 0.3\n'})}),"\n",(0,t.jsx)(e.h2,{id:"practical-manipulation-examples",children:"Practical Manipulation Examples"}),"\n",(0,t.jsx)(e.h3,{id:"picking-and-placing",children:"Picking and Placing"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'class PickAndPlaceController:\n    def __init__(self, robot_params):\n        self.params = robot_params\n        self.grasp_planner = GraspPlanner(robot_params)\n        self.bimanual_controller = BimanualCoordination(robot_params)\n        self.motion_planner = MotionPlanner(robot_params)\n        \n    def pick_object(self, target_object, approach_height=0.1):\n        """\n        Execute picking sequence for a target object\n        """\n        # Step 1: Plan grasp approach\n        grasp_candidates = self.grasp_planner.generate_grasp_candidates(target_object)\n        best_grasp = grasp_candidates[0] if grasp_candidates else None\n        \n        if not best_grasp:\n            raise RuntimeError("No viable grasp found for target object")\n        \n        # Step 2: Plan approach trajectory (above object)\n        approach_pos = list(best_grasp.pose.position)\n        approach_pos[2] += approach_height  # Approach from above\n        \n        # Step 3: Execute approach\n        self.move_to_approach_position(approach_pos, best_grasp.pose.orientation)\n        \n        # Step 4: Execute descent to grasp\n        self.descend_to_grasp(best_grasp.pose)\n        \n        # Step 5: Close gripper with appropriate force\n        self.grasp_with_appropriate_force(target_object)\n        \n        # Step 6: Lift object\n        self.lift_object(0.1)  # Lift 10cm\n        \n        print("Pick operation completed successfully")\n        \n        return {\n            \'status\': \'success\',\n            \'grasp_used\': best_grasp,\n            \'picked_object\': target_object\n        }\n    \n    def place_object(self, target_position, placement_orientation=None):\n        """\n        Execute placing sequence at target position\n        """\n        # Step 1: Plan approach to placement location\n        approach_pos = list(target_position)\n        approach_pos[2] += 0.05  # 5cm above placement position\n        \n        # Step 2: Execute approach\n        if placement_orientation:\n            self.move_to_approach_position(approach_pos, placement_orientation)\n        else:\n            self.move_to_position(approach_pos)  # Maintain current orientation\n        \n        # Step 3: Descend to placement position\n        self.descend_to_placement(target_position)\n        \n        # Step 4: Open gripper to release object\n        self.release_object()\n        \n        # Step 5: Retract from object\n        self.lift_after_placement(0.05)  # Lift 5cm after placing\n        \n        print("Place operation completed successfully")\n        \n        return {\n            \'status\': \'success\',\n            \'placed_at\': target_position\n        }\n    \n    def move_to_approach_position(self, position, orientation):\n        """\n        Move end-effector to approach position with proper orientation\n        """\n        # Plan path from current pose to approach pose\n        target_pose = Pose()\n        target_pose.position.x = position[0]\n        target_pose.position.y = position[1]\n        target_pose.position.z = position[2]\n        target_pose.orientation = orientation\n        \n        # Execute planned trajectory\n        trajectory = self.motion_planner.plan_trajectory_to_pose(target_pose)\n        self.execute_trajectory(trajectory)\n    \n    def descend_to_grasp(self, grasp_pose):\n        """\n        Descend from approach to grasp position\n        """\n        # Execute fine motion control to reach grasp position\n        self.execute_precise_positioning(grasp_pose)\n        \n        # Verify grasp alignment\n        if not self.verify_grasp_alignment(grasp_pose):\n            raise RuntimeError("Grasp alignment verification failed")\n    \n    def grasp_with_appropriate_force(self, object_info):\n        """\n        Close gripper with force appropriate for object properties\n        """\n        # Calculate required grip force based on object properties\n        object_weight = object_info[\'mass\'] * 9.81\n        friction_coeff = object_info.get(\'friction\', 0.6)\n        \n        # Calculate minimum required grip force\n        # F_grip = (weight / friction_coeff) * safety_factor\n        safety_factor = 2.0\n        min_grip_force = (object_weight / friction_coeff) * safety_factor\n        \n        # Apply force control to achieve calculated grip force\n        self.apply_grip_force(min_grip_force)\n        \n        # Verify successful grasp\n        if not self.verify_successful_grasp():\n            raise RuntimeError("Grasp verification failed - object may have slipped")\n    \n    def verify_grasp_alignment(self, expected_pose):\n        """\n        Verify that gripper is properly aligned for grasp\n        """\n        current_pose = self.get_current_gripper_pose()\n        \n        # Check position alignment\n        position_error = np.linalg.norm(\n            np.array([expected_pose.position.x, expected_pose.position.y, expected_pose.position.z]) -\n            np.array([current_pose.position.x, current_pose.position.y, current_pose.position.z])\n        )\n        \n        if position_error > 0.005:  # 5mm threshold\n            return False\n        \n        # Check orientation alignment (simplified)\n        orientation_error = self.calculate_orientation_error(\n            expected_pose.orientation, current_pose.orientation\n        )\n        \n        if orientation_error > 0.1:  # 0.1 radian (~5.7 degrees) threshold\n            return False\n        \n        return True\n    \n    def calculate_orientation_error(self, expected_quat, current_quat):\n        """\n        Calculate the orientation error between two quaternions\n        """\n        # Convert quaternions to rotation matrices\n        expected_rot = R.from_quat([expected_quat.x, expected_quat.y, expected_quat.z, expected_quat.w])\n        current_rot = R.from_quat([current_quat.x, current_quat.y, current_quat.z, current_quat.w])\n        \n        # Calculate relative rotation\n        relative_rot = expected_rot.inv() * current_rot\n        \n        # Return rotation angle as error measure\n        return relative_rot.magnitude()\n\n### Assembly Operations\n\nclass AssemblyController:\n    def __init__(self, robot_params):\n        self.params = robot_params\n        self.alignment_detector = AlignmentDetector()\n        self.force_controller = ForceController(robot_params)\n        \n    def insert_pin_into_hole(self, pin_info, hole_info):\n        """\n        Execute precision insertion task\n        """\n        # Step 1: Align pin with hole axis\n        self.orient_pin_for_insertion(pin_info, hole_info)\n        \n        # Step 2: Approach hole with conservative force control\n        self.approach_hole_with_force_control(hole_info)\n        \n        # Step 3: Insert with compliance control\n        self.insert_with_compliance_control(pin_info, hole_info)\n        \n        # Step 4: Verify successful insertion\n        if not self.verify_insertion_success(hole_info):\n            raise RuntimeError("Insertion verification failed")\n        \n        return {\'status\': \'success\', \'insertion_verified\': True}\n    \n    def orient_pin_for_insertion(self, pin_info, hole_info):\n        """\n        Orient pin to align with hole axis\n        """\n        # Calculate required orientation to align pin with hole\n        hole_axis = self.calculate_hole_axis(hole_info)\n        pin_axis = self.calculate_pin_axis(pin_info)\n        \n        # Calculate rotation needed to align axes\n        rotation_quaternion = self.calculate_alignment_rotation(pin_axis, hole_axis)\n        \n        # Orient gripper to apply this rotation\n        current_pose = self.get_current_gripper_pose()\n        target_orientation = self.combine_orientations(\n            current_pose.orientation, rotation_quaternion\n        )\n        \n        self.set_gripper_orientation(target_orientation)\n    \n    def approach_hole_with_force_control(self, hole_info):\n        """\n        Approach hole using force control to handle misalignments\n        """\n        # Move towards hole while maintaining low insertion force\n        target_force = 5.0  # 5N target insertion force\n        safety_distance = 0.01  # 1cm before hole to start force control\n        \n        # Enable force control\n        self.enable_force_control(axis=\'approach\', target_force=target_force)\n        \n        # Move toward hole until contact or target force reached\n        self.move_approach_direction_with_force_feedback(safety_distance)\n    \n    def insert_with_compliance_control(self, pin_info, hole_info):\n        """\n        Execute insertion using compliance control\n        """\n        # Enable impedance control for compliant insertion\n        self.set_compliant_impedance_for_insertion()\n        \n        # Apply controlled insertion force\n        insertion_force = 10.0  # Controlled insertion force\n        self.apply_controlled_force(insertion_force, \'approach\')\n        \n        # Monitor for successful insertion\n        while not self.detect_insertion_completion():\n            # Continue applying force with compliance\n            self.monitor_insertion_force()\n        \n        # Disable compliance and verify final position\n        self.disable_compliance_control()\n    \n    def detect_insertion_completion(self):\n        """\n        Detect when insertion is complete\n        """\n        # Check for conditions indicating insertion completion:\n        # - Low force in insertion direction\n        # - Stable position/orientation\n        # - Expected depth achieved\n        \n        insertion_force = self.get_current_insertion_force()\n        if insertion_force < 2.0:  # Very low insertion force indicates bottomed out\n            return True\n        \n        return False\n\nclass AlignmentDetector:\n    def __init__(self):\n        pass\n    \n    def detect_misalignment(self, insertion_state):\n        """\n        Detect if pin and hole are misaligned during insertion\n        """\n        # Monitor forces for signs of misalignment\n        forces = insertion_state[\'forces\']\n        \n        # High lateral forces indicate misalignment\n        lateral_force_threshold = 5.0  # N\n        if np.linalg.norm(forces[0:2]) > lateral_force_threshold:  # X, Y forces\n            return True, "High lateral forces detected - possible misalignment"\n        \n        # High twisting torques indicate angular misalignment\n        twist_torque_threshold = 1.0  # N*m\n        if abs(forces[5]) > twist_torque_threshold:  # Z-axis torque\n            return True, "High twisting torque detected - angular misalignment"\n        \n        return False, "Alignment appears adequate"\n'})}),"\n",(0,t.jsx)(e.h2,{id:"grasp-learning-and-adaptation",children:"Grasp Learning and Adaptation"}),"\n",(0,t.jsx)(e.h3,{id:"adaptive-grasping-systems",children:"Adaptive Grasping Systems"}),"\n",(0,t.jsx)(e.p,{children:"Modern manipulation systems include learning components that adapt to new objects and situations:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"class AdaptiveGraspLearner:\n    def __init__(self, robot_params):\n        self.params = robot_params\n        self.experience_db = []  # Store successful and failed grasps\n        self.similarity_matcher = SimilarityMatcher()\n        \n    def learn_from_experience(self, object_features, grasp_attempt, outcome):\n        \"\"\"\n        Learn from grasping experiences\n        \"\"\"\n        experience = {\n            'object_features': object_features,\n            'grasp_configuration': grasp_attempt,\n            'outcome': outcome,  # 'success' or 'failure'\n            'timestamp': time.time(),\n            'environment_conditions': self.get_current_env_conditions()\n        }\n        \n        # Store experience\n        self.experience_db.append(experience)\n        \n        # Update grasp policies based on new experience\n        self.update_grasp_policy(experience)\n    \n    def suggest_grasp_for_new_object(self, new_object_features):\n        \"\"\"\n        Suggest grasp based on learned experiences\n        \"\"\"\n        # Find similar previous experiences\n        similar_experiences = self.find_similar_experiences(new_object_features)\n        \n        # Find successful grasps for similar objects\n        successful_grasps = [\n            exp['grasp_configuration'] \n            for exp in similar_experiences \n            if exp['outcome'] == 'success'\n        ]\n        \n        if not successful_grasps:\n            # Fall back to analytical grasp planning\n            return self.fallback_analytical_grasp(new_object_features)\n        \n        # Select most promising grasp based on past success\n        suggested_grasp = self.select_best_grasp_from_experience(successful_grasps)\n        \n        return suggested_grasp\n    \n    def find_similar_experiences(self, target_features):\n        \"\"\"\n        Find experiences with similar object features\n        \"\"\"\n        similar = []\n        for experience in self.experience_db:\n            similarity = self.similarity_matcher.compute_similarity(\n                target_features, experience['object_features']\n            )\n            \n            if similarity > 0.7:  # Threshold for considering similar\n                similar.append((experience, similarity))\n        \n        # Sort by similarity\n        similar.sort(key=lambda x: x[1], reverse=True)\n        return [exp[0] for exp in similar]  # Return just the experiences\n    \n    def update_grasp_policy(self, experience):\n        \"\"\"\n        Update grasp selection policy based on new experience\n        \"\"\"\n        # This would involve updating a machine learning model\n        # in a real implementation, such as:\n        # - Updating a classifier for grasp success prediction\n        # - Updating a policy network for grasp selection\n        # - Reinforcement learning updates\n        pass\n\nclass SimilarityMatcher:\n    def __init__(self):\n        pass\n    \n    def compute_similarity(self, features1, features2):\n        \"\"\"\n        Compute similarity between two sets of object features\n        \"\"\"\n        # Compare object dimensions\n        if 'dimensions' in features1 and 'dimensions' in features2:\n            dim_similarity = self.compute_dimension_similarity(\n                features1['dimensions'], features2['dimensions']\n            )\n        else:\n            dim_similarity = 0.5  # Neutral if not available\n        \n        # Compare weight\n        if 'mass' in features1 and 'mass' in features2:\n            weight_similarity = self.compute_weight_similarity(\n                features1['mass'], features2['mass']\n            )\n        else:\n            weight_similarity = 0.5\n        \n        # Compare shape\n        if 'shape' in features1 and 'shape' in features2:\n            shape_similarity = 1.0 if features1['shape'] == features2['shape'] else 0.3\n        else:\n            shape_similarity = 0.5\n        \n        # Combine similarities (weighted average)\n        total_similarity = (\n            0.5 * dim_similarity + \n            0.3 * weight_similarity + \n            0.2 * shape_similarity\n        )\n        \n        return total_similarity\n    \n    def compute_dimension_similarity(self, dims1, dims2):\n        \"\"\"\n        Compute similarity based on object dimensions\n        \"\"\"\n        # Calculate relative difference\n        dims1_arr = np.array(dims1)\n        dims2_arr = np.array(dims2)\n        \n        # Relative difference (closer to 1 means more similar)\n        rel_diff = np.abs(dims1_arr - dims2_arr) / np.maximum(dims1_arr, dims2_arr)\n        avg_rel_diff = np.mean(rel_diff)\n        \n        # Convert to similarity (1 - difference)\n        similarity = max(0.0, 1.0 - avg_rel_diff)\n        \n        return similarity\n    \n    def compute_weight_similarity(self, weight1, weight2):\n        \"\"\"\n        Compute similarity based on object weight\n        \"\"\"\n        rel_diff = abs(weight1 - weight2) / max(weight1, weight2)\n        similarity = max(0.0, 1.0 - rel_diff)\n        return similarity\n"})}),"\n",(0,t.jsx)(e.h2,{id:"troubleshooting-common-issues",children:"Troubleshooting Common Issues"}),"\n",(0,t.jsx)(e.h3,{id:"issue-1-grasp-failure",children:"Issue 1: Grasp Failure"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Symptoms"}),": Objects slip or fall during manipulation"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Causes"}),": Insufficient grip force, wrong grasp type, poor contact points"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Solutions"}),":","\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Recalculate required grip force based on object properties"}),"\n",(0,t.jsx)(e.li,{children:"Try alternative grasp types"}),"\n",(0,t.jsx)(e.li,{children:"Verify contact point locations"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"issue-2-collision-during-manipulation",children:"Issue 2: Collision During Manipulation"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Symptoms"}),": Robot collides with environment or itself during manipulation"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Causes"}),": Poor motion planning, inaccurate object localization, narrow workspaces"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Solutions"}),":","\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Improve motion planning with better obstacle detection"}),"\n",(0,t.jsx)(e.li,{children:"Verify object pose estimation accuracy"}),"\n",(0,t.jsx)(e.li,{children:"Increase safety margins in motion planning"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"issue-3-force-control-problems",children:"Issue 3: Force Control Problems"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Symptoms"}),": Excessive forces applied, unstable contact, object damage"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Causes"}),": Incorrect force control parameters, sensor noise, model mismatches"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Solutions"}),":","\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Tune force control gains"}),"\n",(0,t.jsx)(e.li,{children:"Improve sensor filtering"}),"\n",(0,t.jsx)(e.li,{children:"Verify robot dynamics model"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"issue-4-grasp-planning-failure",children:"Issue 4: Grasp Planning Failure"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Symptoms"}),": No valid grasp found for object"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Causes"}),": Complex object geometry, workspace limitations, kinematic constraints"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Solutions"}),":","\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Implement more sophisticated grasp planners"}),"\n",(0,t.jsx)(e.li,{children:"Use geometric simplifications"}),"\n",(0,t.jsx)(e.li,{children:"Consider repositioning object"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Safety First"}),": Always implement force limits and collision avoidance"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Multi-Modal Sensing"}),": Combine vision, force/torque, and tactile feedback"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Graduated Complexity"}),": Start with simple objects and increase complexity"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Robust Planning"}),": Consider uncertainties and implement fault tolerance"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Calibration"}),": Regularly calibrate sensors and hand-eye coordination"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Force Control"}),": Use appropriate force control for delicate operations"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Learning"}),": Incorporate learning mechanisms to improve performance"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Human Oversight"}),": Maintain ability for human intervention when needed"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Simulation Testing"}),": Validate in simulation before real robot experiments"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Modular Design"}),": Separate perception, planning, and control for maintainability"]}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,t.jsx)(e.p,{children:"Manipulation and grasping in humanoid robots involve a complex interplay of perception, planning, control, and learning. Successful manipulation requires:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Effective grasp planning algorithms that consider object properties and robot capabilities"}),"\n",(0,t.jsx)(e.li,{children:"Precise force and impedance control for stable contact interactions"}),"\n",(0,t.jsx)(e.li,{children:"Coordinated control of multiple degrees of freedom"}),"\n",(0,t.jsx)(e.li,{children:"Adaptive systems that learn from experience"}),"\n",(0,t.jsx)(e.li,{children:"Robust handling of uncertainties and disturbances"}),"\n"]}),"\n",(0,t.jsx)(e.p,{children:"These capabilities are essential for humanoid robots to perform meaningful tasks in human environments, allowing them to bridge digital AI models with physical robotic bodies. The field continues to advance with improved sensors, learning algorithms, and robotic hardware, making increasingly sophisticated manipulation tasks possible."})]})}function f(n={}){const{wrapper:e}={...(0,r.R)(),...n.components};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(p,{...n})}):p(n)}},8453(n,e,i){i.d(e,{R:()=>s,x:()=>a});var t=i(6540);const r={},o=t.createContext(r);function s(n){const e=t.useContext(o);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function a(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(r):n.components||r:s(n.components),t.createElement(o.Provider,{value:e},n.children)}}}]);